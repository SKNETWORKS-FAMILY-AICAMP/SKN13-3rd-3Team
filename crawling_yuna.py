import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options

# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
options = Options()
driver = webdriver.Chrome(options=options)

# ìƒì„¸ì •ë³´ ì…€ë ‰í„° ì •ì˜
info_selectors = {
    "ë‚´ìš©ë¬¼ì˜ ìš©ëŸ‰ ë˜ëŠ” ì¤‘ëŸ‰": "#artcInfo > dl:nth-child(2) > dd",
    "ì œí’ˆ ì£¼ìš” ì‚¬ì–‘": "#artcInfo > dl:nth-child(3) > dd",
    "ì‚¬ìš©ê¸°í•œ": "#artcInfo > dl:nth-child(4) > dd",
    "ì‚¬ìš©ë°©ë²•": "#artcInfo > dl:nth-child(5) > dd",
    "ì œì¡°ì—…ì ë“±": "#artcInfo > dl:nth-child(6) > dd",
    "ì œì¡°êµ­": "#artcInfo > dl:nth-child(7) > dd",
    "ì„±ë¶„": "#artcInfo > dl:nth-child(8) > dd",
    "ê¸°ëŠ¥ì„± ì—¬ë¶€": "#artcInfo > dl:nth-child(9) > dd",
    "ì£¼ì˜ì‚¬í•­": "#artcInfo > dl:nth-child(10) > dd",
    "í’ˆì§ˆë³´ì¦ê¸°ì¤€": "#artcInfo > dl:nth-child(11) > dd",
    "ì†Œë¹„ììƒë‹´": "#artcInfo > dl:nth-child(12) > dd"
}

# ë¦¬ë·° ì „ì²´ í˜ì´ì§€ ìˆœíšŒ í•¨ìˆ˜
def collect_reviews_all_pages():
    reviews = []
    while True:
        review_elements = driver.find_elements(By.CSS_SELECTOR, "#gdasList > li")
        for r in review_elements:
            try:
                review_id = r.find_element(By.CSS_SELECTOR, "div.info > div > p.info_user > a.id").text.strip()
                rating = r.find_element(By.CSS_SELECTOR, "div.score_area > span.review_point > span").text.strip()
                skin_type = r.find_element(By.CSS_SELECTOR, "div.poll_sample > dl:nth-child(1) > dd > span").text
                concern = r.find_element(By.CSS_SELECTOR, "div.poll_sample > dl:nth-child(2) > dd > span").text
                sensitivity = r.find_element(By.CSS_SELECTOR, "div.poll_sample > dl:nth-child(3) > dd > span").text
                review_text = r.find_element(By.CSS_SELECTOR, "div.txt_inner").text.strip()

                reviews.append({
                    "ë¦¬ë·° ID": review_id,
                    "ë³„ì ": rating,
                    "í”¼ë¶€íƒ€ì…": skin_type,
                    "í”¼ë¶€ê³ ë¯¼": concern,
                    "ìê·¹ë„": sensitivity,
                    "ë¦¬ë·°": review_text
                })
            except:
                continue

        try:
            current = driver.find_element(By.CSS_SELECTOR, "#gdasContentsArea > div > div.pageing > strong").text
            pages = driver.find_elements(By.CSS_SELECTOR, "#gdasContentsArea > div > div.pageing > a")
            next_pages = [p for p in pages if p.text.isdigit() and int(p.text) > int(current)]
            if next_pages:
                next_pages[0].click()
                time.sleep(1.5)
                continue
        except:
            pass

        try:
            next_block = driver.find_element(By.CSS_SELECTOR, "#gdasContentsArea > div > div.pageing > a.next")
            if next_block.is_displayed():
                next_block.click()
                time.sleep(1.5)
                continue
        except:
            break
        break
    return reviews

product_data = []

# ì „ì²´ ìƒí’ˆ í˜ì´ì§€ ìˆœíšŒ (1~16í˜ì´ì§€)
for page in range(22, 32):
    print(f"ğŸ“„ í˜ì´ì§€ {page} ì²˜ë¦¬ ì¤‘...")
    page_url = f"https://www.oliveyoung.co.kr/store/display/getMCategoryList.do?dispCatNo=100000100010015&fltDispCatNo=&prdSort=02&pageIdx={page}&rowsPerPage=24&searchTypeSort=btn_thumb"
    driver.get(page_url)
    time.sleep(2)

    product_elements = driver.find_elements(By.CSS_SELECTOR, "#Contents > ul > li")

    for product in product_elements:
        try:
            img_tag = product.find_element(By.CSS_SELECTOR, "div > a > img")
            img_url = img_tag.get_attribute("src")
            product_name = img_tag.get_attribute("alt")
            detail_url = product.find_element(By.CSS_SELECTOR, "div > a").get_attribute("href")

            driver.execute_script("window.open(arguments[0]);", detail_url)
            driver.switch_to.window(driver.window_handles[-1])
            time.sleep(2)

            try:
                driver.find_element(By.CSS_SELECTOR, "#buyInfo > a").click()
                time.sleep(1)
            except:
                print(f"[{product_name}] êµ¬ë§¤ì •ë³´ íƒ­ ì—†ìŒ")

            detail_info = {}
            for key, selector in info_selectors.items():
                try:
                    detail_info[key] = driver.find_element(By.CSS_SELECTOR, selector).text.strip()
                except:
                    detail_info[key] = ""

            try:
                driver.find_element(By.CSS_SELECTOR, "#reviewInfo > a").click()
                time.sleep(1.5)
            except:
                print(f"[{product_name}] ë¦¬ë·° íƒ­ ì—†ìŒ")
                driver.close()
                driver.switch_to.window(driver.window_handles[0])
                continue

            reviews = collect_reviews_all_pages()
            for review in reviews:
                data = {
                    "ì œí’ˆëª…": product_name,
                    "ì´ë¯¸ì§€ URL": img_url
                }
                data.update(detail_info)
                data.update(review)
                product_data.append(data)

            driver.close()
            driver.switch_to.window(driver.window_handles[0])
        except Exception as e:
            print(f"ì œí’ˆ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

df = pd.DataFrame(product_data)
df.to_csv("oliveyoung_cream_22_31.csv", index=False, encoding="utf-8-sig")
print("âœ… ì „ì²´ í˜ì´ì§€ì˜ ëª¨ë“  ì œí’ˆ í¬ë¡¤ë§ ì™„ë£Œ")
driver.quit()
